{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import spacy\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"How many combinatory and graph theoretical problems, formerly believed to be plagued by intractability, did Karp's paper address?\"\n",
    "sentence = \"Reducibility Among Combinatorial Problems, in which he showed that 21 diverse combinatorial and graph theoretical problems, each infamous for its computational intractability, are NP-complete. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity(sentences):\n",
    "    entity = []\n",
    "    doc = nlp(sentences)\n",
    "    for ent in doc.ents:\n",
    "        entity.append( (ent.text,ent.label_))\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find cardinal entity\n",
    "#input: sentence\n",
    "def locate_cardinal(sentence):\n",
    "    cardinal = []\n",
    "    for en in get_entity(sentence):\n",
    "        if en[1] == 'CARDINAL' or en[1] == 'QUANTITY':\n",
    "            cardinal.append(en[0])\n",
    "    return cardinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_cardinal2(sentence):\n",
    "    cardinal = []\n",
    "    for en in get_entity(sentence):\n",
    "        if en[1] in ['CARDINAL', 'QUANTITY','PERCENT']:\n",
    "            cardinal.append(en[0])\n",
    "    return cardinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma(word):\n",
    "    token = nlp(word)\n",
    "    lemma = token[0].lemma_\n",
    "    return lemma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_distance(lemma, card, sentence):\n",
    "    sentence_token = nlp(sentence)\n",
    "    idx = 0\n",
    "    obj_idx = 0\n",
    "    card_idx = sentence.find(card)\n",
    "    for s in sentence_token:\n",
    "        #print(s.text)\n",
    "        if s.lemma_ == lemma:\n",
    "            obj_idx = idx\n",
    "#         if s.text == card:\n",
    "#             card_idx = idx\n",
    "        idx += 1\n",
    "    if card_idx - obj_idx == 0:\n",
    "        return 9999\n",
    "    else:\n",
    "        return abs(card_idx - obj_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_how(question, sentence):\n",
    "    noun = get_noun(question)\n",
    "    noun_lemma = get_lemma(noun)\n",
    "    if 'how much' in question.lower():\n",
    "        card_list = locate_cardinal2(sentence)\n",
    "    else:\n",
    "        card_list = locate_cardinal(sentence)\n",
    "    min_dist = 9999\n",
    "    answer = ''\n",
    "    for card in card_list:\n",
    "        #print(card)\n",
    "        dist = calculate_word_distance(noun_lemma, card, sentence)\n",
    "        #print(dist)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            answer = card\n",
    "            #print(answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'NOUN':\n",
    "            return token.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_how(q, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOW MUCH QUESTION\n",
    "#1. how much + verb\n",
    "#2. how much + noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"How much does Victoria produce in Australian pears?\"\n",
    "sentence = \"Victorian farms produce nearly 90% of Australian pears and third of apples.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nearly 90%'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_how(q, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Victorian', 'NORP'),\n",
       " ('nearly 90%', 'PERCENT'),\n",
       " ('Australian', 'NORP'),\n",
       " ('third', 'ORDINAL')]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entity(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
